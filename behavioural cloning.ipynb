{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f466199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_jumping_task\n",
    "from gym_jumping_task.envs.jumping_task import JumpTaskEnv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from env import VanillaEnv\n",
    "from rl.common.buffer2 import Transition, Episode, RolloutBuffer\n",
    "from rl.ppo.policies import ActorCriticNet\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List\n",
    "from rl.ppo.ppo import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d897107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        assert x.shape[0] == y.shape[0]\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6ed4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_expert_trajectories(env):\n",
    "    n_iterations = 10_00\n",
    "    gamma = 0.99\n",
    "\n",
    "    episodes: List[Episode] = []\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        done = False\n",
    "        episode = Episode(discount=gamma)\n",
    "        obs = env.reset()\n",
    "        obstacle_position = env.actualEnv.obstacle_position;\n",
    "        jumping_pixel = obstacle_position-14;\n",
    "        step = 0\n",
    "        episode_reward = 0\n",
    "        while not done:\n",
    "            action = 1 if step==jumping_pixel else 0\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            episode.append(Transition(obs, action, reward, 0))\n",
    "            env.render()\n",
    "            step +=1\n",
    "        episodes.append(episode)\n",
    "        if i % 100==0: print(f\"Episode {i} return {np.sum(episode.rewards())}\")\n",
    "\n",
    "    # get the states, returns and actions out of the episodes\n",
    "    states, actions, values = [], [], []\n",
    "    for episode in episodes:\n",
    "        states += episode.states()\n",
    "        actions += episode.actions()\n",
    "        values += episode.calculate_return()\n",
    "\n",
    "    states, actions, values = np.array(states), np.array(actions), np.array(values)\n",
    "    # vertically add actions and values\n",
    "    targets = np.column_stack((actions, values))\n",
    "\n",
    "    X = torch.tensor(states)\n",
    "    Y = torch.tensor(targets)\n",
    "    data: BCDataset = BCDataset(X, Y)\n",
    "    train_set, val_set = torch.utils.data.random_split(data, [int(len(data)*0.8), int(len(data)*0.2)])\n",
    "\n",
    "    trainloader:DataLoader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    testloader:DataLoader = DataLoader(val_set, batch_size=64, shuffle=True)\n",
    "    return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4ab50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.enable_grad()\n",
    "def train(net:ActorCriticNet, dataLoader: DataLoader, optim_actor, optim_critic, loss_actor, loss_critic) -> tuple:\n",
    "    device = next(net.parameters()).device\n",
    "    net.train()\n",
    "    actor_errors, critic_errors = [], []\n",
    "\n",
    "    for batch in dataLoader:\n",
    "        # X is the observation\n",
    "        # y contains the choosen action and the return estimate from the critic\n",
    "        X, y = batch[0].to(device), batch[1].to(device)\n",
    "        target_actions = y[:,0]\n",
    "        target_returns = y[:,1]\n",
    "\n",
    "        # normalize returns\n",
    "        target_returns = (target_returns - target_returns.mean()) / (target_returns.std() + 1e-5)\n",
    "\n",
    "        pred_action_logits = net.actor.forward(X)\n",
    "        pred_values = net.critic.forward(X).squeeze()\n",
    "\n",
    "        actor_error = loss_actor(pred_action_logits, target_actions.type(torch.LongTensor).to(device))\n",
    "        critic_error = loss_critic(pred_values, target_returns.type(torch.FloatTensor).to(device))\n",
    "\n",
    "        optim_actor.zero_grad()\n",
    "        actor_error.backward()\n",
    "        optim_actor.step()\n",
    "\n",
    "        optim_critic.zero_grad()\n",
    "        critic_error.backward()\n",
    "        optim_critic.step()\n",
    "        \n",
    "        actor_errors.append(actor_error.item())\n",
    "        critic_errors.append(critic_error.item())\n",
    "\n",
    "    return actor_errors, critic_errors\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(net:ActorCriticNet, dataLoader: DataLoader, loss_actor, loss_critic) -> tuple:\n",
    "    device = next(net.parameters()).device\n",
    "    net.eval()\n",
    "    actor_errors, critic_errors = [], []\n",
    "\n",
    "    for batch in dataLoader:\n",
    "        X, y = batch[0].to(device), batch[1].to(device)\n",
    "        target_actions = y[:,0]\n",
    "        target_returns = y[:,1]\n",
    "\n",
    "        # normalize returns\n",
    "        target_returns = (target_returns - target_returns.mean()) / (target_returns.std() + 1e-5)\n",
    "\n",
    "        pred_action_logits = net.actor.forward(X)\n",
    "        pred_values = net.critic.forward(X).squeeze()\n",
    "\n",
    "        actor_errors.append(loss_actor(pred_action_logits, target_actions.type(torch.LongTensor).to(device)).item())\n",
    "        critic_errors.append(loss_critic(pred_values, target_returns.type(torch.FloatTensor).to(device)).item())\n",
    "\n",
    "    return actor_errors, critic_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29337a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_conf = {\n",
    "    \"narrow_grid\": {\n",
    "        # (obstacle_pos, floor_height)\n",
    "        (26, 12), (29, 12), (31, 12), (34, 12),\n",
    "        (26, 20), (29, 20), (31, 20), (34, 20),\n",
    "        (26, 28), (29, 28), (31, 28), (34, 28),\n",
    "    },\n",
    "    \"wide_grid\": {\n",
    "        # (obstacle_pos, floor_height)\n",
    "        (22, 8), (27, 8), (32, 8), (38, 8),\n",
    "        (22, 20), (27, 20), (32, 20), (38, 20),\n",
    "        (22, 32), (27, 32), (32, 32), (38, 32),\n",
    "    },\n",
    "    \"random_grid\": {\n",
    "        # (obstacle_pos, floor_height)\n",
    "        (15, 36), (17, 8), (19, 20), (21, 32),\n",
    "        (26, 20), (30, 4), (32, 24), (34, 36),\n",
    "        (36, 4), (38, 16), (43, 12), (44, 28),\n",
    "    },\n",
    "    \"diagonal_grid\": {\n",
    "        (17, 8), (21, 12), (25, 16), (29, 20),\n",
    "        (32, 24), (36, 28), (40, 32), (44, 36),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce748fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on  cuda\n",
      "Episode 0 return 156.0\n",
      "Episode 100 return 156.0\n",
      "Episode 200 return 156.0\n",
      "Episode 300 return 156.0\n",
      "Episode 400 return 156.0\n",
      "Episode 500 return 156.0\n",
      "Episode 600 return 156.0\n",
      "Episode 700 return 156.0\n",
      "Episode 800 return 156.0\n",
      "Episode 900 return 156.0\n",
      "Epoch 0 Train errors: Actor 0.016, Critic 0.016 \n",
      "              Val errors: Actor 0.000, Critic 0.023 \n",
      "Epoch 1 Train errors: Actor 0.000, Critic 0.000 \n",
      "              Val errors: Actor 0.000, Critic 0.026 \n",
      "Epoch 2 Train errors: Actor 0.000, Critic 0.000 \n",
      "              Val errors: Actor 0.000, Critic 0.026 \n",
      "Epoch 3 Train errors: Actor 0.000, Critic 0.000 \n",
      "              Val errors: Actor 0.000, Critic 0.024 \n",
      "Epoch 4 Train errors: Actor 0.000, Critic 0.000 \n",
      "              Val errors: Actor 0.000, Critic 0.053 \n",
      "Episode 0 return 156.0\n",
      "Episode 100 return 156.0\n",
      "Episode 200 return 156.0\n",
      "Episode 300 return 156.0\n",
      "Episode 400 return 156.0\n",
      "Episode 500 return 156.0\n",
      "Episode 600 return 156.0\n",
      "Episode 700 return 156.0\n",
      "Episode 800 return 156.0\n",
      "Episode 900 return 156.0\n",
      "Epoch 0 Train errors: Actor 0.022, Critic 0.022 \n",
      "              Val errors: Actor 0.000, Critic 0.023 \n",
      "Epoch 1 Train errors: Actor 0.000, Critic 0.000 \n",
      "              Val errors: Actor 0.000, Critic 0.025 \n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Training on \", device)\n",
    "\n",
    "lr = 0.004\n",
    "n_epochs = 5\n",
    "for conf_name in list(train_conf.keys()):\n",
    "    env = VanillaEnv(configurations=list(train_conf[conf_name]),rendering=True)\n",
    "\n",
    "    trainloader, testloader = generate_expert_trajectories(env)\n",
    "    model = ActorCriticNet().to(device);\n",
    "    optim_actor = optim.Adam(model.actor.parameters(), lr=lr);\n",
    "    optim_critic = optim.Adam(model.critic.parameters(), lr=lr)\n",
    "    loss_actor = nn.CrossEntropyLoss()\n",
    "    loss_critic = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        actor_errors, critic_errors = train(model, trainloader, optim_actor, optim_critic, loss_actor, loss_critic)\n",
    "        val_actor_errors, val_critic_errors = evaluate(model, testloader, loss_actor, loss_critic)\n",
    "        print(f\"\"\"Epoch {epoch} Train errors: Actor {np.mean(actor_errors):.3f}, Critic {np.mean(actor_errors):.3f} \n",
    "              Val errors: Actor {np.mean(val_actor_errors):.3f}, Critic {np.mean(val_critic_errors):.3f} \"\"\")\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        ppo = PPO(model, env, optimizer)\n",
    "\n",
    "        ppo.save('./ckpts-final', 'BC-' + conf_name, info={'conf': list(train_conf[conf_name])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384eeea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
