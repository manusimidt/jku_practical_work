{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f466199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym_jumping_task\n",
    "from gym_jumping_task.envs.jumping_task import JumpTaskEnv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from env import VanillaEnv\n",
    "from rl.common.buffer2 import Transition, Episode, RolloutBuffer\n",
    "from rl.ppo.policies import ActorCriticNet\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List\n",
    "from rl.ppo.ppo import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d897107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        assert x.shape[0] == y.shape[0]\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ed4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_expert_trajectories(env, n_episodes):\n",
    "    gamma = 0.99\n",
    "\n",
    "    episodes: List[Episode] = []\n",
    "\n",
    "    for i in range(n_episodes):\n",
    "        done = False\n",
    "        episode = Episode(discount=gamma)\n",
    "        obs = env.reset()\n",
    "        obstacle_position = env.actualEnv.obstacle_position;\n",
    "        jumping_pixel = obstacle_position-14;\n",
    "        step = 0\n",
    "        while not done:\n",
    "            action = 0 if step < jumping_pixel else 1\n",
    "            \n",
    "            # if action == 1 and np.random.choice([1,0], p=[0.2, 0.8]): \n",
    "            #     # with 20% probability generate a non-expert trajectory\n",
    "            #     action = 0\n",
    "            next_obs, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # if action == 1:\n",
    "            #     episode.append(Transition(obs, action, reward, 0))\n",
    "            # else:\n",
    "            #     if np.random.choice([1,0], p=[0.2, 0.8]): \n",
    "            episode.append(Transition(obs, action, reward, 0))\n",
    "            obs = next_obs\n",
    "            env.render()\n",
    "            step +=1\n",
    "\n",
    "        episodes.append(episode)\n",
    "\n",
    "    # get the states, returns and actions out of the episodes\n",
    "    states, actions, values = [], [], []\n",
    "    for episode in episodes:\n",
    "        states += episode.states()\n",
    "        actions += episode.actions()\n",
    "        values += episode.calculate_return()\n",
    "\n",
    "    states, actions, values = np.array(states), np.array(actions), np.array(values)\n",
    "    # vertically add actions and values\n",
    "    targets = np.column_stack((actions, values))\n",
    "\n",
    "    X = torch.tensor(states)\n",
    "    Y = torch.tensor(targets)\n",
    "    data: BCDataset = BCDataset(X, Y)\n",
    "    train_set_length = int(len(data)*0.8)\n",
    "    train_set, val_set = torch.utils.data.random_split(data, [train_set_length, len(data) - train_set_length])\n",
    "\n",
    "    trainloader:DataLoader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    testloader:DataLoader = DataLoader(val_set, batch_size=64, shuffle=True)\n",
    "    return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ab50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.enable_grad()\n",
    "def train(net:ActorCriticNet, dataLoader: DataLoader, optim_actor, optim_critic, \n",
    "          loss_actor=nn.CrossEntropyLoss(), loss_critic=nn.MSELoss()) -> tuple:\n",
    "    device = next(net.parameters()).device\n",
    "    net.train()\n",
    "    actor_errors, critic_errors = [], []\n",
    "\n",
    "    for batch in dataLoader:\n",
    "        # X is the observation\n",
    "        # y contains the choosen action and the return estimate from the critic\n",
    "        X, y = batch[0].to(device), batch[1].to(device)\n",
    "        target_actions = y[:,0]\n",
    "        target_returns = y[:,1]\n",
    "\n",
    "        # normalize returns\n",
    "        target_returns = (target_returns - target_returns.mean()) / (target_returns.std() + 1e-5)\n",
    "\n",
    "        pred_action_logits = net.actor.forward(X)\n",
    "        pred_values = net.critic.forward(X).squeeze()\n",
    "\n",
    "        actor_error = loss_actor(pred_action_logits, target_actions.to(torch.int64))\n",
    "        critic_error = loss_critic(pred_values, target_returns.to(torch.float32))\n",
    "\n",
    "        optim_actor.zero_grad()\n",
    "        actor_error.backward()\n",
    "        optim_actor.step()\n",
    "\n",
    "        optim_critic.zero_grad()\n",
    "        critic_error.backward()\n",
    "        optim_critic.step()\n",
    "        \n",
    "        actor_errors.append(actor_error.item())\n",
    "        critic_errors.append(critic_error.item())\n",
    "\n",
    "    return actor_errors, critic_errors\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(net:ActorCriticNet, dataLoader: DataLoader, loss_actor, loss_critic) -> tuple:\n",
    "    device = next(net.parameters()).device\n",
    "    net.eval()\n",
    "    actor_errors, critic_errors = [], []\n",
    "\n",
    "    for batch in dataLoader:\n",
    "        X, y = batch[0].to(device), batch[1].to(device)\n",
    "        target_actions = y[:,0]\n",
    "        target_returns = y[:,1]\n",
    "\n",
    "        # normalize returns\n",
    "        target_returns = (target_returns - target_returns.mean()) / (target_returns.std() + 1e-5)\n",
    "\n",
    "        pred_action_logits = net.actor.forward(X)\n",
    "        pred_values = net.critic.forward(X).squeeze()\n",
    "\n",
    "        actor_errors.append(loss_actor(pred_action_logits, target_actions.to(torch.int64)).item())\n",
    "        critic_errors.append(loss_critic(pred_values, target_returns.to(torch.float32)).item())\n",
    "\n",
    "    return actor_errors, critic_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29337a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_conf = {\n",
    "    \"narrow_grid\": {\n",
    "        # (obstacle_pos, floor_height)\n",
    "        (26, 12), (29, 12), (31, 12), (34, 12),\n",
    "        (26, 20), (29, 20), (31, 20), (34, 20),\n",
    "        (26, 28), (29, 28), (31, 28), (34, 28),\n",
    "    },\n",
    "    \"wide_grid\": {\n",
    "        # (obstacle_pos, floor_height)\n",
    "        (22, 8), (27, 8), (32, 8), (38, 8),\n",
    "        (22, 20), (27, 20), (32, 20), (38, 20),\n",
    "        (22, 32), (27, 32), (32, 32), (38, 32),\n",
    "    },\n",
    "    \"random_grid\": {\n",
    "        # (obstacle_pos, floor_height)\n",
    "        (15, 36), (17, 8), (19, 20), (21, 32),\n",
    "        (26, 20), (30, 4), (32, 24), (34, 36),\n",
    "        (36, 4), (38, 16), (43, 12), (44, 28),\n",
    "    },\n",
    "    \"diagonal_grid\": {\n",
    "        (17, 8), (21, 12), (25, 16), (29, 20),\n",
    "        (32, 24), (36, 28), (40, 32), (44, 36),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce748fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on  cuda\n",
      "====== Training on BC-vanilla_env-narrow_grid ======\n",
      "Generating 10000 expert episodes...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m env \u001b[39m=\u001b[39m VanillaEnv(configurations\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(train_conf[conf_name]),rendering\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenerating \u001b[39m\u001b[39m{\u001b[39;00mn_episodes\u001b[39m}\u001b[39;00m\u001b[39m expert episodes...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m trainloader, testloader \u001b[39m=\u001b[39m generate_expert_trajectories(env, n_episodes)\n\u001b[0;32m     19\u001b[0m model \u001b[39m=\u001b[39m ActorCriticNet()\u001b[39m.\u001b[39mto(device);\n\u001b[0;32m     20\u001b[0m optim_actor \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mactor\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr);\n",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m, in \u001b[0;36mgenerate_expert_trajectories\u001b[1;34m(env, n_episodes)\u001b[0m\n\u001b[0;32m     26\u001b[0m         obs \u001b[39m=\u001b[39m next_obs\n\u001b[0;32m     27\u001b[0m         env\u001b[39m.\u001b[39mrender()\n\u001b[1;32m---> 28\u001b[0m         step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     30\u001b[0m     episodes\u001b[39m.\u001b[39mappend(episode)\n\u001b[0;32m     32\u001b[0m \u001b[39m# get the states, returns and actions out of the episodes\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m, in \u001b[0;36mgenerate_expert_trajectories\u001b[1;34m(env, n_episodes)\u001b[0m\n\u001b[0;32m     26\u001b[0m         obs \u001b[39m=\u001b[39m next_obs\n\u001b[0;32m     27\u001b[0m         env\u001b[39m.\u001b[39mrender()\n\u001b[1;32m---> 28\u001b[0m         step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     30\u001b[0m     episodes\u001b[39m.\u001b[39mappend(episode)\n\u001b[0;32m     32\u001b[0m \u001b[39m# get the states, returns and actions out of the episodes\u001b[39;00m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\manus\\anaconda3\\envs\\jumping-sb3\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manus\\anaconda3\\envs\\jumping-sb3\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Training on \", device)\n",
    "\n",
    "lr = 0.001\n",
    "n_episodes = 10_000\n",
    "n_epochs = 6\n",
    "\n",
    "environments = ['vanilla_env', 'rnd_aug_env']\n",
    "for environment in environments:\n",
    "    for conf_name in list(train_conf.keys()):\n",
    "        run_name = 'BC-' + environment + '-' + conf_name\n",
    "        print(f\"====== Training on {run_name} ======\")\n",
    "\n",
    "        env = VanillaEnv(configurations=list(train_conf[conf_name]),rendering=True)\n",
    "\n",
    "        print(f\"Generating {n_episodes} expert episodes...\")\n",
    "        trainloader, testloader = generate_expert_trajectories(env, n_episodes)\n",
    "\n",
    "        model = ActorCriticNet().to(device);\n",
    "        optim_actor = optim.Adam(model.actor.parameters(), lr=lr);\n",
    "        optim_critic = optim.Adam(model.critic.parameters(), lr=lr)\n",
    "        loss_actor = nn.CrossEntropyLoss()\n",
    "        loss_critic = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            actor_errors, critic_errors = train(model, trainloader, optim_actor, optim_critic, loss_actor, loss_critic)\n",
    "            val_actor_errors, val_critic_errors = evaluate(model, testloader, loss_actor, loss_critic)\n",
    "\n",
    "            print(f\"\"\"Epoch {epoch} Train errors: Actor {np.mean(actor_errors):.3f}, Critic {np.mean(actor_errors):.3f} Val errors: Actor {np.mean(val_actor_errors):.3f}, Critic {np.mean(val_critic_errors):.3f} \"\"\")\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        ppo = PPO(model, env, optimizer)\n",
    "\n",
    "        ppo.save('./ckpts-final', run_name, info={'conf': list(train_conf[conf_name])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384eeea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
