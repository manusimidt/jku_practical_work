{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e761f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.common.logger import ConsoleLogger, FigureLogger, Tracker\n",
    "from rl.ppo.policies import ActorCriticNet\n",
    "from rl.ppo.ppo import PPO\n",
    "\n",
    "from torch import optim\n",
    "from env import VanillaEnv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b826fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation_grid(grid, training_positions, min_obs_position,\n",
    "                         min_floor_height):\n",
    "    \"\"\"Plots the evaluation grid.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7, 9))\n",
    "    grid_x, grid_y = grid.shape\n",
    "    extent = (0, grid_x, grid_y, 0)\n",
    "    ax.imshow(grid.T, extent=extent, origin='lower', cmap='copper')\n",
    "\n",
    "    x_ticks = np.arange(grid_x)\n",
    "    y_ticks = np.arange(grid_y)\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_yticks(y_ticks)\n",
    "\n",
    "    # ax.tick_params(labelbottom=False, labelleft=False)\n",
    "    ax.set_ylabel(\"Floor height\")\n",
    "    ax.set_xlabel(\"Obstacle position\")\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for (obstacle_pos, floor_height) in training_positions:\n",
    "        pos_index = obstacle_pos - min_obs_position\n",
    "        height_index = floor_height - min_floor_height\n",
    "        ax.text(\n",
    "            pos_index + 0.5,\n",
    "            height_index + 0.5,\n",
    "            'T',\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            color='r',\n",
    "            fontsize='large',\n",
    "            fontweight = 'bold')\n",
    "\n",
    "    ax.grid(color='w', linewidth=1)\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3a0582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obstacle_pos: min: 14, max: 47\n",
    "obstacle_pos = np.array(range(14, 48))\n",
    "# floor_height: min: 0, max: 40\n",
    "floor_height = np.array(range(10, 35))\n",
    "ALL_CONFIGURATIONS = set(itertools.product(obstacle_pos, floor_height))\n",
    "\n",
    "grid = np.zeros((len(obstacle_pos), len(floor_height)))\n",
    "\n",
    "train_conf = {\n",
    "    \"narrow_grid\": set([\n",
    "        # (obstacle_pos, floor_height)\n",
    "        (22, 18), (22, 24),\n",
    "        (26, 18), (26, 24),\n",
    "    ]),\n",
    "    \"wide_grid\": set([\n",
    "        # (obstacle_pos, floor_height)\n",
    "        (18, 16), (18, 26),\n",
    "        (28, 16), (28, 26),\n",
    "    ]),\n",
    "    \"random\": set([\n",
    "        # (obstacle_pos, floor_height)\n",
    "        (43, 29), (39, 33),\n",
    "        (28, 19), (15, 17),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# just quickly check that all training configurations are valid\n",
    "for conf_name in train_conf.keys():\n",
    "    for conf in train_conf[conf_name]:\n",
    "        assert conf in ALL_CONFIGURATIONS, f\"Invalid configuration in {conf_name}\"\n",
    "\n",
    "# TEST_CONFIGURATIONS = ALL_CONFIGURATIONS - TRAINING_CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12fc73a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Training on narrow_grid ======\n",
      "Episode:   1000, return: 24.0\n",
      "Episode:   2000, return: 29.0\n",
      "Episode:   3000, return: 29.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5000\n",
    "for conf_name in train_conf.keys():\n",
    "    print(f\"====== Training on {conf_name} ======\")\n",
    "    env = VanillaEnv(list(train_conf[conf_name]))\n",
    "\n",
    "    policy: ActorCriticNet = ActorCriticNet()\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=0.001)\n",
    "\n",
    "    logger1 = ConsoleLogger(log_every=1000)\n",
    "    logger2 = FigureLogger()\n",
    "    tracker = Tracker(logger1, logger2)\n",
    "\n",
    "    ppo = PPO(policy, env, optimizer, seed=31, tracker=tracker)\n",
    "    ppo.learn(episodes)\n",
    "    ppo.save('./ckpts', conf_name)\n",
    "\n",
    "    fig = logger2.get_figure(fig_size=(8, 4))\n",
    "    fig.suptitle(f\"Training on {conf_name} for {episodes} episodes\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
